"""
clean_data.py - Script de nettoyage des donn√©es immobili√®res

Ce script transforme les donn√©es brutes du scraping en un fichier propre
pr√™t pour l'application Streamlit.

Entr√©e  : data/annonces_raw.csv
Sortie  : data/annonces_clean.csv

Transformations effectu√©es :
1. Extraction des surfaces manquantes depuis les descriptions
2. Suppression des lignes sans surface
3. Cr√©ation de la colonne Ville
4. Cr√©ation de la colonne prix_m2
5. G√©ocodage des villes (latitude, longitude)

"""

import pandas as pd
import re
import time
from pathlib import Path

# Import conditionnel pour le g√©ocodage
try:
    from geopy.geocoders import Nominatim
    GEOPY_AVAILABLE = True
except ImportError:
    GEOPY_AVAILABLE = False
    print("‚ö†Ô∏è  geopy non install√©. Le g√©ocodage sera ignor√©.")
    print("   Pour l'installer : pip install geopy")


# =============================================================================
# CONFIGURATION
# =============================================================================

INPUT_FILE = Path("data/annonces_raw.csv")
OUTPUT_FILE = Path("data/annonces_clean.csv")

# Patterns regex pour extraire la surface depuis la description
SURFACE_PATTERNS = [
    r"(\d+(?:[.,]\d+)?)\s*m¬≤",   # m¬≤ standard (ex: "72.12 m¬≤")
    r"(\d+(?:[.,]\d+)?)\s*m2",    # m2 sans accent (ex: "67 m2")
]

# Configuration Nominatim
NOMINATIM_USER_AGENT = "projet_immobilier_sorbonne"
NOMINATIM_DELAY = 1.0  # D√©lai entre requ√™tes (respect API)


# =============================================================================
# FONCTIONS DE NETTOYAGE
# =============================================================================

def extraire_surface(description: str, type_bien: str = None) -> float | None:
    """
    Extraction INTELLIGENTE de la surface depuis une description.
    
    √âvite les pi√®ges courants : balcons, caves, terrasses, greniers
    qui sont souvent mentionn√©s avec leur surface dans les descriptions.
    
    Priorit√© d'extraction :
    1. Surface Carrez (la plus fiable juridiquement)
    2. Surface "habitable" 
    3. Surface apr√®s "de" ou "d'environ" (formulation standard)
    4. Plus grande surface au-dessus d'un seuil minimum
    
    Le seuil minimum est adapt√© selon le type de bien (studios vs T2+).
    
    Args:
        description: Texte de la description de l'annonce
        type_bien: Type du bien (ex: "Appartement T2") pour adapter le seuil
        
    Returns:
        Surface en m¬≤ (float) ou None si non trouv√©e
    """
    desc = str(description)
    pattern = r"(\d+(?:[.,]\d+)?)\s*m[¬≤2]"
    
    # D√©finir le seuil minimum selon le type de bien
    # Les studios (T0, T1) peuvent √™tre petits, les T2+ rarement < 25m¬≤
    if type_bien and ('T0' in str(type_bien) or 'T1' in str(type_bien)):
        seuil_min = 12
    else:
        seuil_min = 25
    
    # --- Priorit√© 1 : Surface Carrez (mention l√©gale, tr√®s fiable) ---
    carrez = re.search(r"(\d+(?:[.,]\d+)?)\s*m[¬≤2]\s*(?:carrez|loi carrez)", desc, re.IGNORECASE)
    if carrez:
        return float(carrez.group(1).replace(',', '.'))
    
    # --- Priorit√© 2 : Surface habitable ---
    habitable = re.search(r"(\d+(?:[.,]\d+)?)\s*m[¬≤2]\s*habitables?", desc, re.IGNORECASE)
    if habitable:
        return float(habitable.group(1).replace(',', '.'))
    
    # --- Priorit√© 3 : Formulations courantes "de X m¬≤" ---
    # Capture : "appartement de 75 m¬≤", "d'environ 80 m¬≤", "d'une surface de 65 m¬≤"
    formulation = re.search(
        r"(?:de|d'environ|d'une surface de)\s*(\d+(?:[.,]\d+)?)\s*m[¬≤2]", 
        desc, re.IGNORECASE
    )
    if formulation:
        val = float(formulation.group(1).replace(',', '.'))
        if val >= seuil_min:
            return val
    
    # --- Priorit√© 4 : Plus grande surface au-dessus du seuil ---
    # √âvite de prendre la surface d'un balcon (6m¬≤) ou d'une cave (4m¬≤)
    matches = re.findall(pattern, desc, re.IGNORECASE)
    if matches:
        values = [float(m.replace(',', '.')) for m in matches]
        valid = [v for v in values if v >= seuil_min]
        if valid:
            return max(valid)
        # Si tout est sous le seuil, prendre le max (cas tr√®s rare)
        return max(values)
    
    # --- Priorit√© 5 : Pattern "environ X" sans m¬≤ ---
    environ = re.search(r"environ\s*(\d+)", desc, re.IGNORECASE)
    if environ:
        val = float(environ.group(1))
        if val >= seuil_min:
            return val
    
    return None


def extraire_ville(localisation: str) -> str:
    """
    Extrait le nom de la ville depuis la colonne Localisation.
    
    Format attendu : "- Ville - D√©partement (XX)"
    Exemple : "- Paris 8 - Paris (75)" ‚Üí "Paris 8"
    
    Args:
        localisation: Cha√Æne de localisation brute
        
    Returns:
        Nom de la ville nettoy√©
    """
    # Retirer le tiret initial et les espaces
    texte = str(localisation).lstrip('- ').strip()
    
    # Prendre la partie avant le second tiret
    if ' - ' in texte:
        return texte.split(' - ')[0].strip()
    return texte


def extraire_nom_departement(localisation: str) -> str:
    """
    Extrait le nom du d√©partement depuis la colonne Localisation.
    
    Format attendu : "- Ville - D√©partement (XX)"
    Exemple : "- Tarascon - Bouches-du-Rh√¥ne (13)" ‚Üí "Bouches-du-Rh√¥ne"
    
    Args:
        localisation: Cha√Æne de localisation brute
        
    Returns:
        Nom du d√©partement ou cha√Æne vide si non trouv√©
    """
    texte = str(localisation).lstrip('- ').strip()
    
    # Chercher la partie apr√®s le second tiret
    if ' - ' in texte:
        partie_dept = texte.split(' - ')[1].strip()
        # Retirer le code d√©partement entre parenth√®ses : "Bouches-du-Rh√¥ne (13)" ‚Üí "Bouches-du-Rh√¥ne"
        if '(' in partie_dept:
            return partie_dept.split('(')[0].strip()
        return partie_dept
    return ""


def nettoyer_donnees(df: pd.DataFrame) -> pd.DataFrame:
    """
    Applique toutes les transformations de nettoyage.
    
    Args:
        df: DataFrame brut
        
    Returns:
        DataFrame nettoy√©
    """
    print("\nüìä Nettoyage des donn√©es...")
    initial_count = len(df)
    
    # --- 1. Extraction des surfaces manquantes ---
    print("\n1Ô∏è‚É£  Extraction des surfaces depuis les descriptions...")
    mask_missing = df['Surface_m2'].isna()
    missing_count = mask_missing.sum()
    print(f"   Surfaces manquantes : {missing_count}")
    
    # Appliquer l'extraction intelligente (avec type de bien pour adapter le seuil)
    df.loc[mask_missing, 'Surface_m2'] = df.loc[mask_missing].apply(
        lambda row: extraire_surface(row['Description'], row['Type_Bien']), 
        axis=1
    )
    
    recovered = missing_count - df['Surface_m2'].isna().sum()
    print(f"   R√©cup√©r√©es par regex intelligent : {recovered}")
    
    # --- 2. Suppression des lignes sans surface ---
    print("\n2Ô∏è‚É£  Suppression des lignes sans surface...")
    still_missing = df['Surface_m2'].isna().sum()
    df = df.dropna(subset=['Surface_m2']).copy()
    print(f"   Lignes supprim√©es : {still_missing}")
    print(f"   Lignes restantes : {len(df)}")
    
    # --- 3. Cr√©ation de la colonne Ville ---
    print("\n3Ô∏è‚É£  Extraction des noms de ville...")
    df['Ville'] = df['Localisation'].apply(extraire_ville)
    print(f"   Villes uniques : {df['Ville'].nunique()}")
    
    # --- 3bis. Extraction du nom de d√©partement (pour g√©ocodage pr√©cis) ---
    df['Nom_Departement'] = df['Localisation'].apply(extraire_nom_departement)
    
    # --- 4. Calcul du prix au m¬≤ ---
    print("\n4Ô∏è‚É£  Calcul du prix au m¬≤...")
    df['prix_m2'] = (df['Prix'] / df['Surface_m2']).round(2)
    print(f"   Prix/m¬≤ m√©dian : {df['prix_m2'].median():,.0f} ‚Ç¨/m¬≤")
    
    # --- R√©sum√© ---
    print(f"\n‚úÖ Nettoyage termin√© : {initial_count} ‚Üí {len(df)} lignes")
    
    return df


# =============================================================================
# FONCTIONS DE G√âOCODAGE
# =============================================================================

def construire_query_geocodage(ville: str, nom_departement: str = "") -> str:
    """
    Construit la requ√™te de g√©ocodage adapt√©e.
    
    G√®re les cas sp√©ciaux des arrondissements Paris/Lyon/Marseille
    en les convertissant en codes postaux pour une meilleure pr√©cision.
    
    Pour les autres villes, ajoute le nom du d√©partement pour √©viter
    les ambigu√Øt√©s (ex: Tarascon existe dans plusieurs d√©partements).
    
    Args:
        ville: Nom de la ville (ex: "Paris 8", "Grenoble", "Tarascon")
        nom_departement: Nom du d√©partement (ex: "Bouches-du-Rh√¥ne")
        
    Returns:
        Query pour Nominatim (ex: "75008, France", "Tarascon, Bouches-du-Rh√¥ne, France")
    """
    # Pattern pour d√©tecter Paris/Lyon/Marseille + arrondissement
    match = re.search(r"(paris|lyon|marseille)\s*0*(\d+)", str(ville).lower().strip())
    
    if match:
        nom_ville = match.group(1)
        arrondissement = int(match.group(2))
        
        # Codes postaux de base
        base_cp = {
            'paris': 75000,
            'lyon': 69000,
            'marseille': 13000
        }
        
        cp = base_cp.get(nom_ville, 0)
        if cp > 0:
            return f"{cp + arrondissement}, France"
    
    # Cas standard : ajouter le d√©partement pour plus de pr√©cision
    if nom_departement:
        return f"{ville}, {nom_departement}, France"
    else:
        return f"{ville}, France"


def geocoder_villes(df: pd.DataFrame) -> pd.DataFrame:
    """
    Ajoute les coordonn√©es GPS (latitude, longitude) pour chaque ville.
    
    Utilise un cache pour ne g√©ocoder chaque combinaison ville+d√©partement 
    qu'une seule fois. Le nom du d√©partement est ajout√© √† la requ√™te pour
    √©viter les ambigu√Øt√©s (ex: Tarascon existe en Bouches-du-Rh√¥ne et en Ari√®ge).
    
    Args:
        df: DataFrame avec colonnes 'Ville' et 'Nom_Departement'
        
    Returns:
        DataFrame avec colonnes 'latitude' et 'longitude'
    """
    if not GEOPY_AVAILABLE:
        print("\n‚ö†Ô∏è  G√©ocodage ignor√© (geopy non disponible)")
        df['latitude'] = None
        df['longitude'] = None
        return df
    
    print("\nüåç G√©ocodage des villes...")
    
    # Initialiser le g√©ocodeur
    geolocator = Nominatim(user_agent=NOMINATIM_USER_AGENT)
    
    # Identifier les combinaisons (ville, d√©partement) uniques
    # Cela √©vite de g√©ocoder "Tarascon, Bouches-du-Rh√¥ne" et "Tarascon, Ari√®ge" de la m√™me fa√ßon
    couples_uniques = df[['Ville', 'Nom_Departement']].drop_duplicates()
    print(f"   Combinaisons ville+d√©partement uniques : {len(couples_uniques)}")
    print(f"   Temps estim√© : ~{len(couples_uniques)} secondes")
    
    # Cache des coordonn√©es : cl√© = (ville, d√©partement)
    cache = {}
    
    for i, (_, row) in enumerate(couples_uniques.iterrows()):
        ville = row['Ville']
        nom_dept = row['Nom_Departement']
        cache_key = (ville, nom_dept)
        
        try:
            query = construire_query_geocodage(ville, nom_dept)
            location = geolocator.geocode(query, timeout=10)
            
            if location:
                cache[cache_key] = (location.latitude, location.longitude)
            else:
                print(f"   ‚ö†Ô∏è  Non trouv√© : {ville} ({nom_dept})")
                cache[cache_key] = (None, None)
                
        except Exception as e:
            print(f"   ‚ùå Erreur sur {ville} ({nom_dept}) : {e}")
            cache[cache_key] = (None, None)
        
        # Pause pour respecter l'API
        time.sleep(NOMINATIM_DELAY)
        
        # Indicateur de progression
        if (i + 1) % 20 == 0 or (i + 1) == len(couples_uniques):
            print(f"   ... {i + 1}/{len(couples_uniques)} villes trait√©es")
    
    # Appliquer les coordonn√©es au DataFrame
    def get_coords(row):
        key = (row['Ville'], row['Nom_Departement'])
        return cache.get(key, (None, None))
    
    coords = df.apply(get_coords, axis=1)
    df['latitude'] = coords.apply(lambda x: x[0])
    df['longitude'] = coords.apply(lambda x: x[1])
    
    # Stats
    geocoded = df['latitude'].notna().sum()
    print(f"\n   ‚úÖ G√©ocod√©es : {geocoded}/{len(df)} annonces")
    
    return df


# =============================================================================
# FONCTION PRINCIPALE
# =============================================================================

def main():
    """Point d'entr√©e principal du script."""
    
    print("=" * 60)
    print("üè† NETTOYAGE DES DONN√âES IMMOBILI√àRES")
    print("=" * 60)
    
    # --- V√©rification des fichiers ---
    if not INPUT_FILE.exists():
        print(f"\n‚ùå Erreur : Fichier non trouv√© : {INPUT_FILE}")
        print("   Assurez-vous d'avoir ex√©cut√© le scraper d'abord.")
        return
    
    # --- Chargement ---
    print(f"\nüìÇ Chargement de {INPUT_FILE}...")
    df = pd.read_csv(INPUT_FILE)
    print(f"   {len(df)} annonces charg√©es")
    
    # --- Nettoyage ---
    df = nettoyer_donnees(df)
    
    # --- G√©ocodage ---
    df = geocoder_villes(df)
    
    # --- Sauvegarde ---
    print(f"\nüíæ Sauvegarde vers {OUTPUT_FILE}...")
    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
    df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')
    
    # --- R√©sum√© final ---
    print("\n" + "=" * 60)
    print("‚úÖ TRAITEMENT TERMIN√â")
    print("=" * 60)
    print(f"\nFichier cr√©√© : {OUTPUT_FILE}")
    print(f"Lignes : {len(df)}")
    print(f"Colonnes : {list(df.columns)}")
    print(f"\nAper√ßu :")
    print(df[['Ville', 'Prix', 'Surface_m2', 'prix_m2', 'latitude', 'longitude']].head())


if __name__ == "__main__":
    main()
